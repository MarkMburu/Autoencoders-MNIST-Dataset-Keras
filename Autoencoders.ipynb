{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoders.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzIcWgpwS791",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, \n",
        "                       logs={}):\n",
        "       self.log = []\n",
        " \n",
        "    def on_epoch_end(self, \n",
        "                     batch, \n",
        "                     logs={}):\n",
        "       self.log.append(logs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZkqJ9mBSra2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import inspect\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "import keras\n",
        "from keras.layers import Input, Dense, BatchNormalization, Dropout, convolutional, pooling\n",
        "from keras.models import Model\n",
        "\n",
        "import tensorflow\n",
        "\n",
        "class Convolutional2DAutoencoder(BaseEstimator, \n",
        "                                 TransformerMixin):\n",
        "    def __init__(self, \n",
        "                 input_shape=None,\n",
        "                 n_epoch=None,\n",
        "                 batch_size=None,\n",
        "                 encoder_layers=None,\n",
        "                 decoder_layers=None,\n",
        "                 filters=None,\n",
        "                 kernel_size=None,\n",
        "                 strides=None,\n",
        "                 pool_size=None,\n",
        "                 denoising=None):\n",
        "        args, _, _, values = inspect.getargvalues(inspect.currentframe())\n",
        "        values.pop(\"self\")\n",
        "        \n",
        "        for arg, val in values.items():\n",
        "            setattr(self, arg, val)\n",
        "        \n",
        "        loss_history = LossHistory()\n",
        "        \n",
        "        early_stop = keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                                   patience=10)\n",
        "        \n",
        "        reduce_learn_rate = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                                              factor=0.1,\n",
        "                                                              patience=20)\n",
        "        \n",
        "        self.callbacks_list = [loss_history, early_stop, reduce_learn_rate]\n",
        "\n",
        "        for i in range(self.encoder_layers):\n",
        "            if i == 0:\n",
        "                self.input_data = Input(shape=self.input_shape)\n",
        "                self.encoded = BatchNormalization()(self.input_data)\n",
        "                self.encoded = convolutional.Conv2D(filters=self.filters, kernel_size=self.kernel_size, strides=self.strides, activation=\"elu\", padding=\"same\")(self.encoded)\n",
        "                self.encoded = Dropout(rate=0.5)(self.encoded)\n",
        "            elif i > 0 and i < self.encoder_layers - 1:\n",
        "                self.encoded = BatchNormalization()(self.encoded)\n",
        "                self.encoded = convolutional.Conv2D(filters=self.filters, kernel_size=self.kernel_size, strides=self.strides, activation=\"elu\", padding=\"same\")(self.encoded)\n",
        "                self.encoded = Dropout(rate=0.5)(self.encoded)\n",
        "            elif i == self.encoder_layers - 1:\n",
        "                self.encoded = BatchNormalization()(self.encoded)\n",
        "                self.encoded = convolutional.Conv2D(filters=self.filters, kernel_size=self.kernel_size, strides=self.strides, activation=\"elu\", padding=\"same\")(self.encoded)\n",
        "\n",
        "        self.encoded = pooling.MaxPooling2D(strides=self.pool_size, padding=\"same\")(self.encoded)\n",
        "        self.decoded = BatchNormalization()(self.encoded)\n",
        "        self.decoded = convolutional.Conv2D(filters=self.filters, kernel_size=self.kernel_size, strides=self.strides, activation=\"elu\", padding=\"same\")(self.decoded)\n",
        "        self.decoded = convolutional.UpSampling2D(size=self.pool_size)(self.decoded)\n",
        "\n",
        "        for i in range(self.decoder_layers):\n",
        "            if i < self.decoder_layers - 1:\n",
        "                self.decoded = BatchNormalization()(self.decoded)\n",
        "                self.decoded = convolutional.Conv2D(filters=self.filters, kernel_size=self.kernel_size, strides=self.strides, activation=\"elu\", padding=\"same\")(self.decoded)\n",
        "                self.decoded = Dropout(rate=0.5)(self.decoded)\n",
        "            else:\n",
        "                self.decoded = BatchNormalization()(self.decoded)\n",
        "                self.decoded = convolutional.Conv2D(filters=self.filters, kernel_size=self.kernel_size, strides=self.strides, activation=\"elu\", padding=\"same\")(self.decoded)\n",
        "\n",
        "        # 4D tensor with shape: (samples, new_rows, new_cols, filters).\n",
        "        # Remember think of this as a 2D-Lattice across potentially multiple channels per observation.\n",
        "        # Rows represent time and columns represent some quantities of interest that evolve over time.\n",
        "        # Channels might represent different sources of information.\n",
        "        self.decoded = BatchNormalization()(self.decoded)\n",
        "        self.decoded = convolutional.Conv2D(filters=self.input_shape[2], kernel_size=self.kernel_size, strides=self.strides, activation=\"sigmoid\", padding=\"same\")(self.decoded)\n",
        "\n",
        "        self.autoencoder = Model(self.input_data, self.decoded)\n",
        "        self.autoencoder.compile(optimizer=keras.optimizers.Adam(),\n",
        "                                 loss=\"mean_squared_error\")\n",
        "            \n",
        "    def fit(self,\n",
        "            X,\n",
        "            y=None):\n",
        "        self.autoencoder.fit(X if self.denoising is None else X + self.denoising, X,\n",
        "                             validation_split=0.3,\n",
        "                             epochs=self.n_epoch,\n",
        "                             batch_size=self.batch_size,\n",
        "                             shuffle=True,\n",
        "                             callbacks=self.callbacks_list, \n",
        "                             verbose=1)\n",
        "\n",
        "        self.encoded_for_transformer = keras.layers.Flatten()(self.encoded)\n",
        "        \n",
        "        self.encoder = Model(self.input_data, self.encoded_for_transformer)\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def transform(self,\n",
        "                  X):\n",
        "        return self.encoder.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJc_AymJTb5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import inspect\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "import keras\n",
        "from keras.layers import Input, Dense, BatchNormalization, Dropout, local, convolutional, Flatten, Reshape\n",
        "from keras.models import Model\n",
        "\n",
        "import tensorflow\n",
        "\n",
        "class ConvolutionalAutoencoder(BaseEstimator, \n",
        "                               TransformerMixin):\n",
        "    def __init__(self, \n",
        "                 input_shape=None,\n",
        "                 n_epoch=None,\n",
        "                 batch_size=None,\n",
        "                 encoder_layers=None,\n",
        "                 decoder_layers=None,\n",
        "                 filters=None,\n",
        "                 kernel_size=None,\n",
        "                 strides=None,\n",
        "                 pool_size=None,\n",
        "                 denoising=None):\n",
        "        args, _, _, values = inspect.getargvalues(inspect.currentframe())\n",
        "        values.pop(\"self\")\n",
        "        \n",
        "        for arg, val in values.items():\n",
        "            setattr(self, arg, val)\n",
        "        \n",
        "        loss_history = LossHistory()\n",
        "        \n",
        "        early_stop = keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                                   patience=10)\n",
        "        \n",
        "        reduce_learn_rate = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                                              factor=0.1,\n",
        "                                                              patience=20)\n",
        "        \n",
        "        self.callbacks_list = [loss_history, early_stop, reduce_learn_rate]\n",
        "\n",
        "        for i in range(self.encoder_layers):\n",
        "            if i == 0:\n",
        "                self.input_data = Input(shape=self.input_shape)\n",
        "                self.encoded = BatchNormalization()(self.input_data)\n",
        "                self.encoded = keras.layers.Conv1D(filters=self.filters, kernel_size=self.kernel_size, strides=self.strides, activation=\"elu\", padding=\"same\")(self.encoded)\n",
        "                self.encoded = Dropout(rate=0.5)(self.encoded)\n",
        "            elif i > 0 and i < self.encoder_layers - 1:\n",
        "                self.encoded = BatchNormalization()(self.encoded)\n",
        "                self.encoded = keras.layers.Conv1D(filters=self.filters, kernel_size=self.kernel_size, strides=self.strides, activation=\"elu\", padding=\"same\")(self.encoded)\n",
        "                self.encoded = Dropout(rate=0.5)(self.encoded)\n",
        "            elif i == self.encoder_layers - 1:\n",
        "                self.encoded = BatchNormalization()(self.encoded)\n",
        "                self.encoded = keras.layers.Conv1D(filters=self.filters, kernel_size=self.kernel_size, strides=self.strides, activation=\"elu\", padding=\"same\")(self.encoded)\n",
        "\n",
        "        self.encoded = keras.layers.MaxPooling1D(strides=self.pool_size, padding=\"valid\")(self.encoded)\n",
        "        self.encoded = BatchNormalization()(self.encoded)\n",
        "        self.encoded = keras.layers.Conv1D(filters=self.filters, kernel_size=self.kernel_size, strides=self.strides, activation=\"elu\", padding=\"same\")(self.encoded)\n",
        "        self.decoded = keras.layers.UpSampling1D(size=self.pool_size)(self.encoded)\n",
        "\n",
        "        for i in range(self.decoder_layers):\n",
        "            if i < self.decoder_layers - 1:\n",
        "                self.decoded = BatchNormalization()(self.decoded)\n",
        "                self.decoded = keras.layers.Conv1D(filters=self.filters, kernel_size=self.kernel_size, strides=self.strides, activation=\"elu\", padding=\"same\")(self.decoded)\n",
        "                self.decoded = Dropout(rate=0.5)(self.decoded)\n",
        "            else:\n",
        "                self.decoded = BatchNormalization()(self.decoded)\n",
        "                self.decoded = keras.layers.Conv1D(filters=self.filters, kernel_size=self.kernel_size, strides=self.strides, activation=\"elu\", padding=\"same\")(self.decoded)\n",
        "\n",
        "        # 3D tensor with shape: (batch_size, new_steps, filters).\n",
        "        # Remember think of this as a 2D-Lattice per observation.\n",
        "        # Rows represent time and columns represent some quantities of interest that evolve over time.\n",
        "        self.decoded = BatchNormalization()(self.decoded)\n",
        "        self.decoded = keras.layers.Conv1D(filters=self.input_shape[1], kernel_size=self.kernel_size, strides=self.strides, activation=\"sigmoid\", padding=\"same\")(self.decoded)\n",
        "\n",
        "        self.autoencoder = Model(self.input_data, self.decoded)\n",
        "        self.autoencoder.compile(optimizer=keras.optimizers.Adam(),\n",
        "                                 loss=\"mean_squared_error\")\n",
        "            \n",
        "    def fit(self,\n",
        "            X,\n",
        "            y=None):\n",
        "        self.autoencoder.fit(X if self.denoising is None else X + self.denoising, X,\n",
        "                             validation_split=0.3,\n",
        "                             epochs=self.n_epoch,\n",
        "                             batch_size=self.batch_size,\n",
        "                             shuffle=True,\n",
        "                             callbacks=self.callbacks_list, \n",
        "                             verbose=1)\n",
        "\n",
        "        self.encoded_for_transformer = keras.layers.Flatten()(self.encoded)\n",
        "        \n",
        "        self.encoder = Model(self.input_data, self.encoded_for_transformer)\n",
        "\n",
        "        return self\n",
        "    \n",
        "    def transform(self,\n",
        "                  X):\n",
        "        return self.encoder.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9W0kXCeSPnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "def get_session(gpu_fraction=0.25,\n",
        "                allow_soft_placement=True,\n",
        "                log_device_placement=True):\n",
        "    \"\"\"\n",
        "    https://groups.google.com/forum/#!topic/keras-users/MFUEY9P1sc8\n",
        "    \"\"\"\n",
        "    num_threads = os.environ.get(\"OMP_NUM_THREADS\")\n",
        "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
        "\n",
        "    if num_threads:\n",
        "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, intra_op_parallelism_threads=num_threads, allow_soft_placement=allow_soft_placement, log_device_placement=log_device_placement))\n",
        "    else:\n",
        "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement=allow_soft_placement, log_device_placement=log_device_placement))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LuA4nKRT_Cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import inspect\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "import keras\n",
        "from keras.layers import Input, Activation, Dense, Dropout, LSTM, RepeatVector, TimeDistributed\n",
        "from keras.models import Model\n",
        "\n",
        "import tensorflow\n",
        "\n",
        "class Seq2SeqAutoencoder(BaseEstimator, \n",
        "                         TransformerMixin):\n",
        "    def __init__(self, \n",
        "                 input_shape=None,\n",
        "                 n_epoch=None,\n",
        "                 batch_size=None,\n",
        "                 encoder_layers=None,\n",
        "                 decoder_layers=None,\n",
        "                 n_hidden_units=None,\n",
        "                 encoding_dim=None,\n",
        "                 stateful=None,\n",
        "                 denoising=None):\n",
        "        args, _, _, values = inspect.getargvalues(inspect.currentframe())\n",
        "        values.pop(\"self\")\n",
        "        \n",
        "        for arg, val in values.items():\n",
        "            setattr(self, arg, val)\n",
        "        \n",
        "        loss_history = LossHistory()\n",
        "        \n",
        "        early_stop = keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                                   patience=10)\n",
        "        \n",
        "        reduce_learn_rate = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                                              factor=0.1,\n",
        "                                                              patience=20)\n",
        "        \n",
        "        self.callbacks_list = [loss_history, early_stop, reduce_learn_rate]\n",
        "        \n",
        "        # 2D-lattice with time on the x-axis (across rows) and with space on the y-axis (across columns).\n",
        "        if self.stateful is True:\n",
        "            self.input_data = Input(batch_shape=self.input_shape)\n",
        "            self.n_rows = self.input_shape[1]\n",
        "            self.n_cols = self.input_shape[2]\n",
        "        else:\n",
        "            self.input_data = Input(shape=self.input_shape)\n",
        "            self.n_rows = self.input_shape[0]\n",
        "            self.n_cols = self.input_shape[1]\n",
        "\n",
        "        for i in range(self.encoder_layers):\n",
        "            if i == 0:\n",
        "                # Returns a sequence of n_rows vectors of dimension n_hidden_units.\n",
        "                self.encoded = LSTM(units=self.n_hidden_units, return_sequences=True, stateful=self.stateful)(self.input_data)\n",
        "            else:\n",
        "                self.encoded = LSTM(units=self.n_hidden_units, return_sequences=True, stateful=self.stateful)(self.encoded)\n",
        "\n",
        "        # Returns 1 vector of dimension encoding_dim.\n",
        "        self.encoded = LSTM(units=self.encoding_dim, return_sequences=False, stateful=self.stateful)(self.encoded)\n",
        "\n",
        "        # Returns a sequence containing n_rows vectors where each vector is of dimension encoding_dim.\n",
        "        # output_shape: (None, n_rows, encoding_dim).\n",
        "        self.decoded = RepeatVector(self.n_rows)(self.encoded)\n",
        "\n",
        "        for i in range(self.decoder_layers):\n",
        "            self.decoded = LSTM(units=self.n_hidden_units, return_sequences=True, stateful=self.stateful)(self.decoded)\n",
        "        \n",
        "        # If return_sequences is True: 3D tensor with shape (batch_size, timesteps, units).\n",
        "        # Else: 2D tensor with shape (batch_size, units).\n",
        "        # Note that n_rows here is timesteps and n_cols here is units.\n",
        "        # If return_state is True: a list of tensors. \n",
        "        # The first tensor is the output. The remaining tensors are the last states, each with shape (batch_size, units).\n",
        "        # If stateful is True: the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.\n",
        "        # For LSTM (not LSTM) If unroll is True: the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences.\n",
        "        self.decoded = LSTM(units=self.n_cols, return_sequences=True, stateful=self.stateful)(self.decoded)\n",
        "\n",
        "        self.autoencoder = Model(self.input_data, self.decoded)\n",
        "        self.autoencoder.compile(optimizer=keras.optimizers.Adam(),\n",
        "                                 loss=\"mean_squared_error\")\n",
        "            \n",
        "    def fit(self,\n",
        "            X,\n",
        "            y=None):\n",
        "        self.autoencoder.fit(X if self.denoising is None else X + self.denoising, X,\n",
        "                             validation_split=0.3,\n",
        "                             epochs=self.n_epoch,\n",
        "                             batch_size=self.batch_size,\n",
        "                             shuffle=True,\n",
        "                             callbacks=self.callbacks_list,\n",
        "                             verbose=1)\n",
        "\n",
        "        self.encoder = Model(self.input_data, self.encoded)\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def transform(self,\n",
        "                  X):\n",
        "        return self.encoder.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3trkVVYPU21s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import inspect\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "import keras\n",
        "from keras.layers import Input, Dense, BatchNormalization, Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "import tensorflow\n",
        "\n",
        "\n",
        "class VanillaAutoencoder(BaseEstimator, \n",
        "                         TransformerMixin):\n",
        "    def __init__(self, \n",
        "                 n_feat=None,\n",
        "                 n_epoch=None,\n",
        "                 batch_size=None,\n",
        "                 encoder_layers=None,\n",
        "                 decoder_layers=None,\n",
        "                 n_hidden_units=None,\n",
        "                 encoding_dim=None,\n",
        "                 denoising=None):\n",
        "        args, _, _, values = inspect.getargvalues(inspect.currentframe())\n",
        "        values.pop(\"self\")\n",
        "        \n",
        "        for arg, val in values.items():\n",
        "            setattr(self, arg, val)\n",
        "        \n",
        "        loss_history = LossHistory()\n",
        "        \n",
        "        early_stop = keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                                   patience=10)\n",
        "        \n",
        "        reduce_learn_rate = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                                              factor=0.1,\n",
        "                                                              patience=20)\n",
        "        \n",
        "        self.callbacks_list = [loss_history, early_stop, reduce_learn_rate]\n",
        "        \n",
        "        for i in range(self.encoder_layers):\n",
        "            if i == 0:\n",
        "                self.input_data = Input(shape=(self.n_feat,))\n",
        "                self.encoded = BatchNormalization()(self.input_data)\n",
        "                self.encoded = Dense(units=self.n_hidden_units, activation=\"elu\")(self.encoded)\n",
        "                self.encoded = Dropout(rate=0.5)(self.encoded)\n",
        "            elif i > 0 and i < self.encoder_layers - 1:\n",
        "                self.encoded = BatchNormalization()(self.encoded)\n",
        "                self.encoded = Dense(units=self.n_hidden_units, activation=\"elu\")(self.encoded)\n",
        "                self.encoded = Dropout(rate=0.5)(self.encoded)\n",
        "            elif i == self.encoder_layers - 1:\n",
        "                self.encoded = BatchNormalization()(self.encoded)\n",
        "                self.encoded = Dense(units=self.n_hidden_units, activation=\"elu\")(self.encoded)\n",
        "        \n",
        "        self.encoded = BatchNormalization()(self.encoded)\n",
        "        self.encoded = Dense(units=self.encoding_dim, activation=\"sigmoid\")(self.encoded)\n",
        "\n",
        "        for i in range(self.decoder_layers):\n",
        "            if i == 0:\n",
        "                self.decoded = BatchNormalization()(self.encoded)\n",
        "                self.decoded = Dense(units=self.n_hidden_units, activation=\"elu\")(self.decoded)\n",
        "                self.decoded = Dropout(rate=0.5)(self.decoded)\n",
        "            elif i > 0 and i < self.decoder_layers - 1:\n",
        "                self.decoded = BatchNormalization()(self.decoded)\n",
        "                self.decoded = Dense(units=self.n_hidden_units, activation=\"elu\")(self.decoded)\n",
        "                self.decoded = Dropout(rate=0.5)(self.decoded)\n",
        "            elif i == self.decoder_layers - 1:\n",
        "                self.decoded = BatchNormalization()(self.decoded)\n",
        "                self.decoded = Dense(units=self.n_hidden_units, activation=\"elu\")(self.decoded)\n",
        "        \n",
        "        # Output would have shape: (batch_size, n_feat).\n",
        "        self.decoded = BatchNormalization()(self.decoded)\n",
        "        self.decoded = Dense(units=self.n_feat, activation=\"sigmoid\")(self.decoded)\n",
        "\n",
        "        self.autoencoder = Model(self.input_data, self.decoded)\n",
        "        self.autoencoder.compile(optimizer=keras.optimizers.Adam(),\n",
        "                                 loss=\"mean_squared_error\")\n",
        "           \n",
        "    def fit(self,\n",
        "            X,\n",
        "            y=None):\n",
        "        self.autoencoder.fit(X if self.denoising is None else X + self.denoising, X,\n",
        "                             validation_split=0.3,\n",
        "                             epochs=self.n_epoch,\n",
        "                             batch_size=self.batch_size,\n",
        "                             shuffle=True,\n",
        "                             callbacks=self.callbacks_list, \n",
        "                             verbose=1)\n",
        "\n",
        "        self.encoder = Model(self.input_data, self.encoded)\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def transform(self,\n",
        "                  X):\n",
        "        return self.encoder.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynexHS_BVHlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import inspect\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "import keras\n",
        "from keras.layers import Input, Dense, BatchNormalization, Dropout, Lambda, add\n",
        "from keras.models import Model, Sequential\n",
        "\n",
        "import tensorflow\n",
        "\n",
        "class VariationalAutoencoder(BaseEstimator, \n",
        "                             TransformerMixin):\n",
        "    def __init__(self, \n",
        "                 n_feat=None,\n",
        "                 n_epoch=None,\n",
        "                 batch_size=None,\n",
        "                 encoder_layers=None,\n",
        "                 decoder_layers=None,\n",
        "                 n_hidden_units=None,\n",
        "                 encoding_dim=None,\n",
        "                 denoising=None):\n",
        "        args, _, _, values = inspect.getargvalues(inspect.currentframe())\n",
        "        values.pop(\"self\")\n",
        "        \n",
        "        for arg, val in values.items():\n",
        "            setattr(self, arg, val)\n",
        "        \n",
        "        loss_history = LossHistory()\n",
        "        \n",
        "        early_stop = keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                                   patience=10)\n",
        "        \n",
        "        reduce_learn_rate = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                                              factor=0.1,\n",
        "                                                              patience=20)\n",
        "        \n",
        "        self.callbacks_list = [loss_history, early_stop, reduce_learn_rate]\n",
        "\n",
        "        for i in range(self.encoder_layers):\n",
        "            if i == 0:\n",
        "                self.input_data = Input(shape=(self.n_feat,))\n",
        "                self.encoded = BatchNormalization()(self.input_data)\n",
        "                self.encoded = Dense(units=self.n_hidden_units, activation=\"elu\")(self.encoded)\n",
        "                self.encoded = Dropout(rate=0.5)(self.encoded)\n",
        "            elif i > 0 and i < self.encoder_layers - 1:\n",
        "                self.encoded = BatchNormalization()(self.encoded)\n",
        "                self.encoded = Dense(units=self.n_hidden_units, activation=\"elu\")(self.encoded)\n",
        "                self.encoded = Dropout(rate=0.5)(self.encoded)\n",
        "            elif i == self.encoder_layers - 1:\n",
        "                self.encoded = BatchNormalization()(self.encoded)\n",
        "                self.encoded = Dense(units=self.n_hidden_units, activation=\"elu\")(self.encoded)\n",
        "        \n",
        "        self.mu = Dense(units=self.encoding_dim, activation=\"linear\")(self.encoded)\n",
        "        self.log_sigma = Dense(units=self.encoding_dim, activation=\"linear\")(self.encoded)\n",
        "        z = Lambda(self.sample_z, output_shape=(self.encoding_dim,))([self.mu, self.log_sigma])\n",
        "\n",
        "        self.decoded_layers_dict = {}\n",
        "        \n",
        "        decoder_counter = 0\n",
        "        \n",
        "        for i in range(self.decoder_layers):\n",
        "            if i == 0:\n",
        "                self.decoded_layers_dict[decoder_counter] = BatchNormalization()\n",
        "                decoder_counter += 1\n",
        "                self.decoded_layers_dict[decoder_counter] = Dense(units=self.n_hidden_units, activation=\"elu\")\n",
        "                decoder_counter += 1\n",
        "                self.decoded_layers_dict[decoder_counter] = Dropout(rate=0.5)\n",
        "\n",
        "                self.decoded = self.decoded_layers_dict[decoder_counter - 2](z)\n",
        "                self.decoded = self.decoded_layers_dict[decoder_counter - 1](self.decoded)\n",
        "                self.decoded = self.decoded_layers_dict[decoder_counter](self.decoded)\n",
        "\n",
        "                decoder_counter += 1\n",
        "            elif i > 0 and i < self.decoder_layers - 1:\n",
        "                self.decoded_layers_dict[decoder_counter] = BatchNormalization()\n",
        "                decoder_counter += 1\n",
        "                self.decoded_layers_dict[decoder_counter] = Dense(units=self.n_hidden_units, activation=\"elu\")\n",
        "                decoder_counter += 1\n",
        "                self.decoded_layers_dict[decoder_counter] = Dropout(rate=0.5)\n",
        "\n",
        "                self.decoded = self.decoded_layers_dict[decoder_counter - 2](self.decoded)\n",
        "                self.decoded = self.decoded_layers_dict[decoder_counter - 1](self.decoded)\n",
        "                self.decoded = self.decoded_layers_dict[decoder_counter](self.decoded)\n",
        "\n",
        "                decoder_counter += 1\n",
        "            elif i == self.decoder_layers - 1:\n",
        "                self.decoded_layers_dict[decoder_counter] = BatchNormalization()\n",
        "                decoder_counter += 1\n",
        "                self.decoded_layers_dict[decoder_counter] = Dense(units=self.n_hidden_units, activation=\"elu\")\n",
        "\n",
        "                self.decoded = self.decoded_layers_dict[decoder_counter - 1](self.decoded)\n",
        "                self.decoded = self.decoded_layers_dict[decoder_counter](self.decoded)\n",
        "                decoder_counter += 1\n",
        "        \n",
        "        # Output would have shape: (batch_size, n_feat).\n",
        "        self.decoded_layers_dict[decoder_counter] = Dense(units=self.n_feat, activation=\"sigmoid\")\n",
        "        self.decoded = self.decoded_layers_dict[decoder_counter](self.decoded)\n",
        "\n",
        "        self.autoencoder = Model(self.input_data, self.decoded)\n",
        "        self.autoencoder.compile(optimizer=keras.optimizers.Adam(),\n",
        "                                 loss=self.vae_loss)\n",
        "            \n",
        "    def fit(self,\n",
        "            X,\n",
        "            y=None):\n",
        "        self.autoencoder.fit(X if self.denoising is None else X + self.denoising, X,\n",
        "                             validation_split=0.3,\n",
        "                             epochs=self.n_epoch,\n",
        "                             batch_size=self.batch_size,\n",
        "                             shuffle=True,\n",
        "                             callbacks=self.callbacks_list, \n",
        "                             verbose=1)\n",
        "\n",
        "        self.encoder = Model(self.input_data, self.mu)\n",
        "\n",
        "        self.generator_input = Input(shape=(self.encoding_dim,))\n",
        "        self.generator_output = None\n",
        "        decoder_counter = 0\n",
        "            \n",
        "        for i in range(self.decoder_layers):\n",
        "            if i == 0:\n",
        "                self.generator_output = self.decoded_layers_dict[decoder_counter](self.generator_input)\n",
        "                decoder_counter += 1\n",
        "                self.generator_output = self.decoded_layers_dict[decoder_counter](self.generator_output)\n",
        "                decoder_counter += 1\n",
        "                self.generator_output = self.decoded_layers_dict[decoder_counter](self.generator_output)\n",
        "                decoder_counter += 1\n",
        "            elif i > 0 and i < self.decoder_layers - 1:\n",
        "                self.generator_output = self.decoded_layers_dict[decoder_counter](self.generator_output)\n",
        "                decoder_counter += 1\n",
        "                self.generator_output = self.decoded_layers_dict[decoder_counter](self.generator_output)\n",
        "                decoder_counter += 1\n",
        "                self.generator_output = self.decoded_layers_dict[decoder_counter](self.generator_output)\n",
        "                decoder_counter += 1\n",
        "            elif i == self.decoder_layers - 1:\n",
        "                self.generator_output = self.decoded_layers_dict[decoder_counter](self.generator_output)\n",
        "                decoder_counter += 1\n",
        "                self.generator_output = self.decoded_layers_dict[decoder_counter](self.generator_output)\n",
        "                decoder_counter += 1\n",
        "\n",
        "        self.generator_output = self.decoded_layers_dict[decoder_counter](self.generator_output)\n",
        "\n",
        "        self.generator = Model(self.generator_input, self.generator_output)\n",
        "                \n",
        "        return self\n",
        "    \n",
        "    def transform(self,\n",
        "                  X):\n",
        "        return self.encoder.predict(X)\n",
        "    \n",
        "    def sample_z(self,\n",
        "                 args):\n",
        "        mu_, log_sigma_ = args\n",
        "        eps = keras.backend.random_normal(shape=(keras.backend.shape(mu_)[0], self.encoding_dim),\n",
        "                                          mean=0.0,\n",
        "                                          stddev=1.0)\n",
        "        out = mu_ + keras.backend.exp(log_sigma_ / 2) * eps\n",
        "            \n",
        "        return out\n",
        "    \n",
        "    def vae_loss(self,\n",
        "                 y_true,\n",
        "                 y_pred):\n",
        "        recon = keras.backend.sum(x=keras.backend.square(y_pred - y_true))\n",
        "        kl = -0.5 * keras.backend.sum(x=1.0 + self.log_sigma - keras.backend.exp(self.log_sigma) - keras.backend.square(self.mu))\n",
        "        return recon + kl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPxULmjlI5Hs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7384b45a-e7ee-4b06-a662-e1cdfd8c8125"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import sys\n",
        "import importlib\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer, RobustScaler, StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from scipy.stats import norm\n",
        "\n",
        "import keras\n",
        "from keras import backend as bkend\n",
        "from keras.datasets import cifar10, mnist\n",
        "from keras.layers import Dense, BatchNormalization, Dropout, Flatten, convolutional, pooling\n",
        "from keras import metrics\n",
        "\n",
        "# import keras.backend.tensorflow_backend as KTF\n",
        "# KTF.set_session(get_session(gpu_fraction=0.75, allow_soft_placement=True, log_device_placement=False))\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "from plotnine import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "importlib.reload(bkend)\n",
        "\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 3354497126807408506\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 10616564208856510467\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyBeOl7TV1A6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9dc7b743-a86f-4dc6-94ca-274ed30b7a8f"
      },
      "source": [
        "mnist = mnist.load_data()\n",
        "(X_train, y_train), (X_test, y_test) = mnist\n",
        "X_train = np.reshape(X_train, [X_train.shape[0], X_train.shape[1] * X_train.shape[1]])\n",
        "X_test = np.reshape(X_test, [X_test.shape[0], X_test.shape[1] * X_test.shape[1]])\n",
        "y_train = y_train.ravel()\n",
        "y_test = y_test.ravel()\n",
        "X_train = X_train.astype(\"float32\")\n",
        "X_test = X_test.astype(\"float32\")\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgccJnmEWQ-X",
        "colab_type": "text"
      },
      "source": [
        "#Scikit-learn\n",
        "We will use the Python machine learning library scikit-learn for data transformation and the classification task. Note that we will code the autoencoders as scikit-learn transformers such that they can be readily used by scikit-learn pipelines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJXLnxYOWD4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler_classifier = MinMaxScaler(feature_range=(0.0, 1.0))\n",
        "logistic = linear_model.LogisticRegression(random_state=666)\n",
        "linear_mod = linear_model.ElasticNetCV()\n",
        "lb = LabelBinarizer()\n",
        "lb = lb.fit(y_train.reshape(y_train.shape[0], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiUCvEjrWpsg",
        "colab_type": "text"
      },
      "source": [
        "#MNIST: No Autoencoders\n",
        "We run the MNIST dataset without using an autoencoder. The 2 dimensional tensor of pixel intensities per image for MNIST images are of dimension $\\mathbb{R}^{28 \\times 28}$. We reshape them as a 1 dimensional tensor of dimension $\\mathbb{R}^{784}$ per image. Therefore we have 784, i.e., $28 \\times 28 = 784$, features for this task per image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKM1zp6sWKx7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "a66abcdc-dd27-4c34-d58e-a4ed2802842c"
      },
      "source": [
        "pipe_base = Pipeline(steps=[(\"scaler_classifier\", scaler_classifier),\n",
        "                            (\"classifier\", logistic)])\n",
        "pipe_base = pipe_base.fit(X_train, y_train)\n",
        "\n",
        "acc_base = pipe_base.score(X_test, y_test)\n",
        "\n",
        "print(\"The accuracy score for the MNIST classification task without autoencoders: %.6f%%.\" % (acc_base * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy score for the MNIST classification task without autoencoders: 92.590000%.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqj0CO8BXNlN",
        "colab_type": "text"
      },
      "source": [
        "#MNIST: PCA\n",
        "We use a PCA filter that picks the number of components that explain $99\\%$ of the variation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDfmxbS8XEAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "8f1d3c05-2b91-475e-dec0-7a6dd299097c"
      },
      "source": [
        "\n",
        "pipe_pca = Pipeline(steps=[(\"PCA\", PCA(n_components=0.99)),\n",
        "                           (\"scaler_classifier\", scaler_classifier),\n",
        "                           (\"classifier\", logistic)])\n",
        "pipe_pca = pipe_base.fit(X_train, y_train)\n",
        "\n",
        "acc_pca = pipe_pca.score(X_test, y_test)\n",
        "\n",
        "print(\"The accuracy score for the MNIST classification task with PCA: %.6f%%.\" % (acc_pca * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy score for the MNIST classification task with PCA: 92.590000%.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7SnR3H3Xsuj",
        "colab_type": "text"
      },
      "source": [
        "#MNIST: Vanilla Autoencoders\n",
        "An autoencoder is an unsupervised learning technique where the objective is to learn a set of features that can be used to reconstruct the input data.\n",
        "\n",
        "Our input data is $X \\in \\mathbb{R}^{N \\times 784}$. An encoder function $E$ maps this to a set of $K$ features such that $E: \\mathbb{R}^{N \\times 784} \\rightarrow \\mathbb{R}^{N \\times K}$. A decoder function $D$ uses the set of $K$ features to reconstruct the input data such that $D: \\mathbb{R}^{N \\times K} \\rightarrow \\mathbb{R}^{N \\times 784}$.\n",
        "\n",
        "$$\\begin{align*}\n",
        "&amp;X \\in \\mathbb{R}^{N \\times 784} \\\\\n",
        "&amp;E: \\mathbb{R}^{N \\times 784} \\rightarrow \\mathbb{R}^{N \\times K} \\\\\n",
        "&amp;D: \\mathbb{R}^{N \\times K} \\rightarrow \\mathbb{R}^{N \\times 784}\n",
        "\\end{align*}$$\n",
        "Lets denote the reconstructed data as $\\tilde{X} = D(E(X))$. The goal is to learn the encoding and decoding functions such that we minimize the difference between the input data and the reconstructed data. An example for an objective function for this task can be the Mean Squared Error (MSE) such that $\\frac{1}{N}||\\tilde{X} - X||^{2}_{2}$.\n",
        "\n",
        "We learn the encoding and decoding functions by minimizing the MSE using the parameters that define the encoding and decoding functions: The gradient of the MSE with respect to the parameters are calculated using the chain rule, i.e., backpropagation, and used to update the parameters via an optimization algorithm such as Stochastic Gradient Descent (SGD).\n",
        "\n",
        "Lets assume we have a single layer autoencoder using the Exponential Linear Unit (ELU) activation function, batch normalization, dropout and the Adaptive Moment (Adam) optimization algorithm. $B$ is the batch size, $K$ is the number of features.\n",
        "\n",
        "Exponential Linear Unit: The activation function is smooth everywhere and avoids the vanishing gradient problem as the output takes on negative values when the input is negative. $\\alpha$ is taken to be $1.0$.\n",
        "$$\\begin{align*}\n",
        "H_{\\alpha}(z) &amp;= \n",
        "\\begin{cases}\n",
        "&amp;\\alpha\\left(\\exp(z) - 1\\right) \\quad \\text{if} \\quad z &lt; 0 \\\\\n",
        "&amp;z \\quad \\text{if} \\quad z \\geq 0\n",
        "\\end{cases} \\\\\n",
        "\\frac{dH_{\\alpha}(z)}{dz} &amp;= \n",
        "\\begin{cases}\n",
        "&amp;\\alpha\\left(\\exp(z)\\right) \\quad \\text{if} \\quad z &lt; 0 \\\\\n",
        "&amp;1 \\quad \\text{if} \\quad z \\geq 0\n",
        "\\end{cases} \n",
        "\\end{align*}$$\n",
        "Batch Normalization: The idea is to transform the inputs into a hidden layer's activation functions. We standardize or normalize first using the mean and variance parameters on a per feature basis and then learn a set of scaling and shifting parameters on a per feature basis that transforms the data. The following equations describe this layer succintly: The parameters we learn in this layer are $\\left(\\mu_{j}, \\sigma_{j}^2, \\beta_{j}, \\gamma_{j}\\right) \\quad \\forall j \\in \\{1, \\dots, K\\}$.\n",
        "$$\\begin{align*}\n",
        "\\mu_{j} &amp;= \\frac{1}{B} \\sum_{i=1}^{B} X_{i,j} \\quad &amp;\\forall j \\in \\{1, \\dots, K\\} \\\\\n",
        "\\sigma_{j}^2 &amp;= \\frac{1}{B} \\sum_{i=1}^{B} \\left(X_{i,j} - \\mu_{j}\\right)^2 \\quad &amp;\\forall j \\in \\{1, \\dots, K\\} \\\\\n",
        "\\hat{X}_{:,j} &amp;= \\frac{X_{:,j} - \\mu_{j}}{\\sqrt{\\sigma_{j}^2 + \\epsilon}} \\quad &amp;\\forall j \\in \\{1, \\dots, K\\} \\\\\n",
        "Z_{:,j} &amp;= \\gamma_{j}\\hat{X}_{:,j} + \\beta_{j} \\quad &amp;\\forall j \\in \\{1, \\dots, K\\}\n",
        "\\end{align*}$$\n",
        "Dropout: This regularization technique simply drops the outputs from input and hidden units with a certain probability say $50\\%$.\n",
        "\n",
        "Adam Optimization Algorithm: This adaptive algorithm combines ideas from the Momentum and RMSProp optimization algorithms. The goal is to have some memory of past gradients which can guide future parameters updates. The following equations for the algorithm succintly describe this method assuming $\\theta$ is our set of parameters to be learnt and $\\eta$ is the learning rate.\n",
        "\n",
        "$$\\begin{align*}\n",
        "m &amp;\\leftarrow \\beta_{1}m + \\left[\\left(1 - \\beta_{1}\\right)\\left(\\nabla_{\\theta}\\text{MSE}\\right)\\right] \\\\\n",
        "s &amp;\\leftarrow \\beta_{2}s + \\left[\\left(1 - \\beta_{2}\\right)\\left(\\nabla_{\\theta}\\text{MSE} \\otimes \\nabla_{\\theta}\\text{MSE} \\right)\\right] \\\\\n",
        "\\theta &amp;\\leftarrow \\theta - \\eta m \\oslash \\sqrt{s + \\epsilon}\n",
        "\\end{align*}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "082_MhakXkL5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a36b755-e308-42f2-84b8-6fe1ee10143a"
      },
      "source": [
        "autoencoder = VanillaAutoencoder(n_feat=X_train.shape[1],\n",
        "                                 n_epoch=50,\n",
        "                                 batch_size=100,\n",
        "                                 encoder_layers=3,\n",
        "                                 decoder_layers=3,\n",
        "                                 n_hidden_units=1000,\n",
        "                                 encoding_dim=500,\n",
        "                                 denoising=None)\n",
        "\n",
        "print(autoencoder.autoencoder.summary())\n",
        "\n",
        "pipe_autoencoder = Pipeline(steps=[(\"autoencoder\", autoencoder),\n",
        "                                   (\"scaler_classifier\", scaler_classifier),\n",
        "                                   (\"classifier\", logistic)])\n",
        "\n",
        "pipe_autoencoder = pipe_autoencoder.fit(X_train, y_train)\n",
        "\n",
        "acc_autoencoder = pipe_autoencoder.score(X_test, y_test)\n",
        "\n",
        "print(\"The accuracy score for the MNIST classification task with an autoencoder: %.6f%%.\" % (acc_autoencoder * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1000)              785000    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 500)               2000      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1000)              501000    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 784)               784784    \n",
            "=================================================================\n",
            "Total params: 6,604,420\n",
            "Trainable params: 6,589,852\n",
            "Non-trainable params: 14,568\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "420/420 [==============================] - 56s 134ms/step - loss: 0.0479 - val_loss: 0.0176\n",
            "Epoch 2/50\n",
            "420/420 [==============================] - 56s 134ms/step - loss: 0.0213 - val_loss: 0.0147\n",
            "Epoch 3/50\n",
            "420/420 [==============================] - 56s 133ms/step - loss: 0.0192 - val_loss: 0.0128\n",
            "Epoch 4/50\n",
            "420/420 [==============================] - 56s 133ms/step - loss: 0.0181 - val_loss: 0.0122\n",
            "Epoch 5/50\n",
            "420/420 [==============================] - 56s 133ms/step - loss: 0.0174 - val_loss: 0.0118\n",
            "Epoch 6/50\n",
            "420/420 [==============================] - 56s 133ms/step - loss: 0.0168 - val_loss: 0.0113\n",
            "Epoch 7/50\n",
            "420/420 [==============================] - 56s 132ms/step - loss: 0.0165 - val_loss: 0.0110\n",
            "Epoch 8/50\n",
            "420/420 [==============================] - 55s 132ms/step - loss: 0.0161 - val_loss: 0.0108\n",
            "Epoch 9/50\n",
            "420/420 [==============================] - 55s 132ms/step - loss: 0.0159 - val_loss: 0.0106\n",
            "Epoch 10/50\n",
            "420/420 [==============================] - 56s 133ms/step - loss: 0.0156 - val_loss: 0.0105\n",
            "Epoch 11/50\n",
            "420/420 [==============================] - 56s 132ms/step - loss: 0.0154 - val_loss: 0.0103\n",
            "Epoch 12/50\n",
            "420/420 [==============================] - 56s 132ms/step - loss: 0.0152 - val_loss: 0.0101\n",
            "Epoch 13/50\n",
            "420/420 [==============================] - 56s 133ms/step - loss: 0.0150 - val_loss: 0.0100\n",
            "Epoch 14/50\n",
            "420/420 [==============================] - 56s 133ms/step - loss: 0.0149 - val_loss: 0.0099\n",
            "Epoch 15/50\n",
            "420/420 [==============================] - 56s 134ms/step - loss: 0.0147 - val_loss: 0.0097\n",
            "Epoch 16/50\n",
            "420/420 [==============================] - 56s 133ms/step - loss: 0.0146 - val_loss: 0.0096\n",
            "Epoch 17/50\n",
            "420/420 [==============================] - 56s 133ms/step - loss: 0.0145 - val_loss: 0.0095\n",
            "Epoch 18/50\n",
            "420/420 [==============================] - 55s 132ms/step - loss: 0.0144 - val_loss: 0.0095\n",
            "Epoch 19/50\n",
            "420/420 [==============================] - 56s 133ms/step - loss: 0.0142 - val_loss: 0.0094\n",
            "Epoch 20/50\n",
            "420/420 [==============================] - 56s 133ms/step - loss: 0.0142 - val_loss: 0.0094\n",
            "Epoch 21/50\n",
            "420/420 [==============================] - 56s 132ms/step - loss: 0.0140 - val_loss: 0.0091\n",
            "Epoch 22/50\n",
            "420/420 [==============================] - 55s 131ms/step - loss: 0.0139 - val_loss: 0.0091\n",
            "Epoch 23/50\n",
            "420/420 [==============================] - 55s 130ms/step - loss: 0.0138 - val_loss: 0.0090\n",
            "Epoch 24/50\n",
            "420/420 [==============================] - 55s 131ms/step - loss: 0.0137 - val_loss: 0.0089\n",
            "Epoch 25/50\n",
            "420/420 [==============================] - 54s 130ms/step - loss: 0.0136 - val_loss: 0.0088\n",
            "Epoch 26/50\n",
            "420/420 [==============================] - 55s 130ms/step - loss: 0.0135 - val_loss: 0.0088\n",
            "Epoch 27/50\n",
            "420/420 [==============================] - 55s 130ms/step - loss: 0.0134 - val_loss: 0.0088\n",
            "Epoch 28/50\n",
            "420/420 [==============================] - 55s 130ms/step - loss: 0.0133 - val_loss: 0.0087\n",
            "Epoch 29/50\n",
            "420/420 [==============================] - 54s 129ms/step - loss: 0.0133 - val_loss: 0.0088\n",
            "Epoch 30/50\n",
            "420/420 [==============================] - 54s 129ms/step - loss: 0.0132 - val_loss: 0.0086\n",
            "Epoch 31/50\n",
            "420/420 [==============================] - 54s 128ms/step - loss: 0.0131 - val_loss: 0.0086\n",
            "Epoch 32/50\n",
            "420/420 [==============================] - 54s 129ms/step - loss: 0.0131 - val_loss: 0.0086\n",
            "Epoch 33/50\n",
            "420/420 [==============================] - 55s 130ms/step - loss: 0.0130 - val_loss: 0.0084\n",
            "Epoch 34/50\n",
            "420/420 [==============================] - 55s 130ms/step - loss: 0.0129 - val_loss: 0.0085\n",
            "Epoch 35/50\n",
            "420/420 [==============================] - 55s 130ms/step - loss: 0.0128 - val_loss: 0.0084\n",
            "Epoch 36/50\n",
            "420/420 [==============================] - 55s 130ms/step - loss: 0.0127 - val_loss: 0.0083\n",
            "Epoch 37/50\n",
            "420/420 [==============================] - 55s 131ms/step - loss: 0.0127 - val_loss: 0.0084\n",
            "Epoch 38/50\n",
            "420/420 [==============================] - 55s 131ms/step - loss: 0.0126 - val_loss: 0.0083\n",
            "Epoch 39/50\n",
            "420/420 [==============================] - 55s 131ms/step - loss: 0.0126 - val_loss: 0.0082\n",
            "Epoch 40/50\n",
            "420/420 [==============================] - 55s 131ms/step - loss: 0.0125 - val_loss: 0.0081\n",
            "Epoch 41/50\n",
            "420/420 [==============================] - 55s 131ms/step - loss: 0.0125 - val_loss: 0.0082\n",
            "Epoch 42/50\n",
            "420/420 [==============================] - 55s 130ms/step - loss: 0.0124 - val_loss: 0.0080\n",
            "Epoch 43/50\n",
            "420/420 [==============================] - 55s 130ms/step - loss: 0.0123 - val_loss: 0.0081\n",
            "Epoch 44/50\n",
            "420/420 [==============================] - 58s 139ms/step - loss: 0.0123 - val_loss: 0.0080\n",
            "Epoch 45/50\n",
            "420/420 [==============================] - 56s 133ms/step - loss: 0.0122 - val_loss: 0.0080\n",
            "Epoch 46/50\n",
            "420/420 [==============================] - 56s 133ms/step - loss: 0.0122 - val_loss: 0.0079\n",
            "Epoch 47/50\n",
            "420/420 [==============================] - 56s 134ms/step - loss: 0.0121 - val_loss: 0.0078\n",
            "Epoch 48/50\n",
            "420/420 [==============================] - 56s 133ms/step - loss: 0.0121 - val_loss: 0.0081\n",
            "Epoch 49/50\n",
            "420/420 [==============================] - 56s 132ms/step - loss: 0.0120 - val_loss: 0.0078\n",
            "Epoch 50/50\n",
            "420/420 [==============================] - 55s 132ms/step - loss: 0.0120 - val_loss: 0.0079\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The accuracy score for the MNIST classification task with an autoencoder: 96.610000%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKDg3SAyYMz1",
        "colab_type": "text"
      },
      "source": [
        "#MNIST: Denoising Autoencoders\n",
        "The idea here is to add some noise to the data and try to learn a set of robust features that can reconstruct the non-noisy data from the noisy data. The MSE objective functions is as follows, $\\frac{1}{N}||D(E(X + \\epsilon)) - X||^{2}_{2}$, where $\\epsilon$ is some noise term.\n",
        "\n",
        "$$\\begin{align*}\n",
        "&amp;X \\in \\mathbb{R}^{N \\times 784} \\\\\n",
        "&amp;E: \\mathbb{R}^{N \\times 784} \\rightarrow \\mathbb{R}^{N \\times K} \\\\\n",
        "&amp;D: \\mathbb{R}^{N \\times K} \\rightarrow \\mathbb{R}^{N \\times 784}\n",
        "\\end{align*}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWDnJZTLYGrp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1691ace6-58d5-48de-ee49-4adbbe01b0bd"
      },
      "source": [
        "noise = 0.10 * np.reshape(np.random.uniform(low=0.0, \n",
        "                                            high=1.0, \n",
        "                                            size=X_train.shape[0] * X_train.shape[1]), \n",
        "                          [X_train.shape[0], X_train.shape[1]])\n",
        "\n",
        "denoising_autoencoder = VanillaAutoencoder(n_feat=X_train.shape[1],\n",
        "                                           n_epoch=50,\n",
        "                                           batch_size=100,\n",
        "                                           encoder_layers=3,\n",
        "                                           decoder_layers=3,\n",
        "                                           n_hidden_units=1000,\n",
        "                                           encoding_dim=500,\n",
        "                                           denoising=noise)\n",
        "\n",
        "print(denoising_autoencoder.autoencoder.summary())\n",
        "\n",
        "pipe_denoising_autoencoder = Pipeline(steps=[(\"autoencoder\", denoising_autoencoder),\n",
        "                                             (\"scaler_classifier\", scaler_classifier),\n",
        "                                             (\"classifier\", logistic)])\n",
        "\n",
        "pipe_denoising_autoencoder = pipe_denoising_autoencoder.fit(X_train, y_train)\n",
        "\n",
        "acc_denoising_autoencoder = pipe_denoising_autoencoder.score(X_test, y_test)\n",
        "\n",
        "print(\"The accuracy score for the MNIST classification task with a denoising autoencoder: %.6f%%.\" % (acc_denoising_autoencoder * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1000)              785000    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 500)               2000      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1000)              501000    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 784)               784784    \n",
            "=================================================================\n",
            "Total params: 6,604,420\n",
            "Trainable params: 6,589,852\n",
            "Non-trainable params: 14,568\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "420/420 [==============================] - 56s 133ms/step - loss: 0.0483 - val_loss: 0.0181\n",
            "Epoch 2/50\n",
            "420/420 [==============================] - 56s 133ms/step - loss: 0.0217 - val_loss: 0.0154\n",
            "Epoch 3/50\n",
            "420/420 [==============================] - 55s 131ms/step - loss: 0.0197 - val_loss: 0.0136\n",
            "Epoch 4/50\n",
            "420/420 [==============================] - 54s 130ms/step - loss: 0.0186 - val_loss: 0.0130\n",
            "Epoch 5/50\n",
            "420/420 [==============================] - 54s 129ms/step - loss: 0.0178 - val_loss: 0.0123\n",
            "Epoch 6/50\n",
            "420/420 [==============================] - 54s 129ms/step - loss: 0.0173 - val_loss: 0.0117\n",
            "Epoch 7/50\n",
            "420/420 [==============================] - 55s 130ms/step - loss: 0.0168 - val_loss: 0.0115\n",
            "Epoch 8/50\n",
            "420/420 [==============================] - 56s 133ms/step - loss: 0.0165 - val_loss: 0.0111\n",
            "Epoch 9/50\n",
            "420/420 [==============================] - 55s 132ms/step - loss: 0.0162 - val_loss: 0.0109\n",
            "Epoch 10/50\n",
            "358/420 [========================>.....] - ETA: 7s - loss: 0.0159"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY5aFXXrZ4gp",
        "colab_type": "text"
      },
      "source": [
        "#MNIST: Sequence to Sequence Autoencoders\n",
        "Given our mortgage default example a potentially more useful deep learning architecture might be the Recurrent Neural Network (RNN), specifically their state of the art variant the Long Short Term Memory (LSTM) network. The goal is to explicitly take into account the sequential nature of the raw data.\n",
        "\n",
        "$$\\begin{align*}\n",
        "&amp;X \\in \\mathbb{R}^{N \\times 28 \\times 28} \\\\\n",
        "&amp;E: \\mathbb{R}^{N \\times 28 \\times 28} \\rightarrow \\mathbb{R}^{N \\times K} \\\\\n",
        "&amp;D: \\mathbb{R}^{N \\times K} \\rightarrow \\mathbb{R}^{N \\times 28 \\times 28}\n",
        "\\end{align*}$$\n",
        "The gradients in a RNN depend on the parameter matrices defined for the model. Simply put these parameter matrices can end up being multiplied many times over and hence cause two major problems for learning: Exploding and vanishing gradients. If the spectral radius of the parameter matrices, i.e., the maximum absolute value of the eigenvalues of a matrix, is more than 1 then gradients can become large enough, i.e., explode in value, such that learning diverges and similarly if the spectral radius is less than 1 then gradients can become small, i.e., vanish in value, such that the next best transition for the parameters cannot be reliably calculated. Appropriate calculation of the gradient is important for estimating the optimal set of parameters that define a machine learning method and the LSTM network overcomes these problems in a vanilla RNN. We now define the LSTM network for 1 time step, i.e., 1 memory cell.\n",
        "\n",
        "We calculate the value of the input gate, the value of the memory cell state at time period $t$ where $f(x)$ is some activation function and the value of the forget gate:\n",
        "\n",
        "$$\\begin{align*}\n",
        "i_{t} &amp;= \\sigma(W_{i}x_{t} + U_{i}h_{t-1} + b_{i}) \\\\\n",
        "\\tilde{c_{t}} &amp;= f(W_{c}x_{t} + U_{c}h_{t-1} + b_{c}) \\\\\n",
        "f_{t} &amp;= \\sigma(W_{f}x_{t} + U_{f}h_{t-1} + b_{f})\n",
        "\\end{align*}$$\n",
        "The forget gate controls the amount the LSTM remembers, i.e., the value of the memory cell state at time period $t-1$ where $\\otimes$ is the hadamard product:\n",
        "\n",
        "$$\\begin{align*}\n",
        "c_{t} = i_{t} \\otimes \\tilde{c_{t}} + f_{t} \\otimes c_{t-1} \n",
        "\\end{align*}$$\n",
        "With the updated state of the memory cell we calculate the value of the outputs gate and finally the output value itself:\n",
        "\n",
        "$$\\begin{align*}\n",
        "o_{t} &amp;= \\sigma(W_{o}x_{t} + U_{o}h_{t-1} + b_{o}) \\\\\n",
        "h_{t} &amp;= o_{t} \\otimes f(c_{t})\n",
        "\\end{align*}$$\n",
        "We can have a wide variety of LSTM architectures such as the convolutional LSTM where note that we replace the matrix multiplication operators in the input gate, the initial estimate $\\tilde{c_{t}}$ of the memory cell state, the forget gate and the output gate by the convolution operator $*$:\n",
        "\n",
        "$$\\begin{align*}\n",
        "i_{t} &amp;= \\sigma(W_{i} * x_{t} + U_{i} * h_{t-1} + b_{i}) \\\\\n",
        "\\tilde{c_{t}} &amp;= f(W_{c} * x_{t} + U_{c} * h_{t-1} + b_{c}) \\\\\n",
        "f_{t} &amp;= \\sigma(W_{f} * x_{t} + U_{f} * h_{t-1} + b_{f}) \\\\\n",
        "c_{t} &amp;= i_{t} \\otimes \\tilde{c_{t}} + f_{t} \\otimes c_{t-1} \\\\ \n",
        "o_{t} &amp;= \\sigma(W_{o} * x_{t} + U_{o} * h_{t-1} + b_{o}) \\\\\n",
        "h_{t} &amp;= o_{t} \\otimes f(c_{t})\n",
        "\\end{align*}$$\n",
        "Another popular variant is the peephole LSTM where the gates are allowed to peep at the memory cell state:\n",
        "\n",
        "$$\\begin{align*}\n",
        "i_{t} &amp;= \\sigma(W_{i}x_{t} + U_{i}h_{t-1} + V_{i}c_{t-1} + b_{i}) \\\\\n",
        "\\tilde{c_{t}} &amp;= f(W_{c}x_{t} + U_{c}h_{t-1} + V_{c}c_{t-1} + b_{c}) \\\\\n",
        "f_{t} &amp;= \\sigma(W_{f}x_{t} + U_{f}h_{t-1} + V_{f}c_{t-1} + b_{f}) \\\\\n",
        "c_{t} &amp;= i_{t} \\otimes \\tilde{c_{t}} + f_{t} \\otimes c_{t-1} \\\\ \n",
        "o_{t} &amp;= \\sigma(W_{o}x_{t} + U_{o}h_{t-1} + V_{o}c_{t} + b_{o}) \\\\\n",
        "h_{t} &amp;= o_{t} \\otimes f(c_{t})\n",
        "\\end{align*}$$\n",
        "The goal for the sequence to sequence autoencoder is to create a representation of the raw data using a LSTM as an encoder. This representation will be a sequence of vectors say, $h_{1}, \\dots, h_{T}$, learnt from a sequence of raw data vectors say, $x_{1}, \\dots, x_{T}$. The final vector of the representation, $h_{T}$, is our encoded representation, also called a context vector. This context vector is repeated as many times as the length of the sequence such that it can be used as an input to a decoder which is yet another LSTM. The decoder LSTM will use this context vector to recontruct the sequence of raw data vectors, $\\tilde{x_{1}}, \\dots, \\tilde{x_{T}}$. If the context vector is useful in the recontruction task then it can be further used for other tasks such as predicting default risk as given in our example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJplKRDNY-E4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "seq2seq_autoencoder = Seq2SeqAutoencoder(input_shape=(int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5))),\n",
        "                                         n_epoch=50,\n",
        "                                         batch_size=100,\n",
        "                                         encoder_layers=3,\n",
        "                                         decoder_layers=3,\n",
        "                                         n_hidden_units=200,\n",
        "                                         encoding_dim=200,\n",
        "                                         stateful=False,\n",
        "                                         denoising=None)\n",
        "\n",
        "print(seq2seq_autoencoder.autoencoder.summary())\n",
        "\n",
        "pipe_seq2seq_autoencoder = Pipeline(steps=[(\"autoencoder\", seq2seq_autoencoder),\n",
        "                                           (\"scaler_classifier\", scaler_classifier),\n",
        "                                           (\"classifier\", logistic)])\n",
        "\n",
        "pipe_seq2seq_autoencoder = pipe_seq2seq_autoencoder.fit(np.reshape(X_train, [X_train.shape[0], int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5))]),\n",
        "                                                        y_train)\n",
        "\n",
        "acc_seq2seq_autoencoder = pipe_seq2seq_autoencoder.score(np.reshape(X_test, [X_test.shape[0], int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5))]), y_test)\n",
        "\n",
        "print(\"The accuracy score for the MNIST classification task with a sequence to sequence autoencoder: %.6f%%.\" % (acc_seq2seq_autoencoder * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIISb1VKaW8V",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#MNIST: Variational Autoencoders\n",
        "We now combine Bayesian inference with deep learning by using variational inference to train a vanilla autoencoder. This moves us towards generative modelling which can have further use cases in semi-supervised learning. The other benefit of training using Bayesian inference is that we can be more robust to higher capacity deep learners, i.e., avoid overfitting.\n",
        "\n",
        "$$\\begin{align*}\n",
        "&amp;X \\in \\mathbb{R}^{N \\times 784} \\\\\n",
        "&amp;E: \\mathbb{R}^{N \\times 784} \\rightarrow \\mathbb{R}^{N \\times K} \\\\\n",
        "&amp;D: \\mathbb{R}^{N \\times K} \\rightarrow \\mathbb{R}^{N \\times 784}\n",
        "\\end{align*}$$\n",
        "Assume $X$ is our raw data while $Z$ is our learnt representation.\n",
        "We have a prior belief on our learnt representation:\n",
        "$$\\begin{align*}\n",
        "p(Z)\n",
        "\\end{align*}$$\n",
        "The posterior distribution for our learnt representation is:\n",
        "$$\\begin{align*}\n",
        "p(Z|X)=\\frac{p(X|Z)p(Z)}{p(X)}\n",
        "\\end{align*}$$\n",
        "The marginal likelihood, $p(X)$, is often intractable causing the posterior distribution, $p(Z|X)$, to be intractable:\n",
        "$$\\begin{align*}\n",
        "p(X)=\\int_{Z}p(X|Z)p(Z)dZ\n",
        "\\end{align*}$$\n",
        "We therefore need an approximate posterior distribution via variational inference that can deal with the intractability. This additionally also provides the benefit of dealing with large scale datasets as generally Markov Chain Monte Carlo (MCMC) methods are not well suited for large scale datasets. One might also consider Laplace approximation for the approximate posterior distribution however we will stick with variational inference as it allows a richer set of approximations compared to Laplace approximation. Laplace approximation simply amounts to finding the Maximum A Posteriori (MAP) estimate to an augmented likelihood optimization, taking the negative of the inverse of the Hessian at the MAP estimate to estimate the variance-covariance matrix and finally use the variance-covariance matrix with a multivariate Gaussian distribution or some other appropriate multivariate distribution.\n",
        "\n",
        "Assume that our approximate posterior distribution, which is also our probabilistic encoder, is given as:\n",
        "\n",
        "$$\\begin{align*}\n",
        "q(Z|X)\n",
        "\\end{align*}$$\n",
        "Our probabilistic decoder is given by:\n",
        "$$\\begin{align*}\n",
        "p(X|Z)\n",
        "\\end{align*}$$\n",
        "Given our setup above with regards to an encoder and a decoder let us now write down the optimization problem where $\\theta$ are the generative model parameters while $\\phi$ are the variational parameters:\n",
        "$$\\begin{align*}\n",
        "\\log{p(X)}= \\underbrace{D_{KL}(q(Z|X)||p(Z|X))}_\\text{Intractable as p(Z|X) is intractable} + \\underbrace{\\mathcal{L}(\\theta, \\phi|X)}_\\text{Evidence Lower Bound or ELBO}\n",
        "\\end{align*}$$\n",
        "Note that $D_{KL}(q(Z|X)||p(Z|X))$ is non-negative therefore that makes the ELBO a lower bound on $\\log{p(X)}$:\n",
        "$$\\begin{align*}\n",
        "\\log{p(X)}\\geq \\mathcal{L}(\\theta, \\phi|X) \\quad \\text{as} \\quad D_{KL}(q(Z|X)||p(Z|X)) \\geq 0\n",
        "\\end{align*}$$\n",
        "Therefore we can alter our optimization problem to look only at the ELBO:\n",
        "$$\\begin{align*}\n",
        "\\mathcal{L}(\\theta, \\phi|X) &amp;= \\mathbb{E}_{q(Z|X)}\\left[\\log{p(X,Z)} - \\log{q(Z|X)}\\right] \\\\\n",
        "&amp;= \\mathbb{E}_{q(Z|X)}\\left[\\underbrace{\\log{p(X|Z)}}_\\text{Reconstruction error} + \\log{p(Z)} - \\log{q(Z|X)}\\right] \\\\\n",
        "&amp;= \\mathbb{E}_{q(Z|X)}\\left[\\underbrace{\\log{p(X|Z)}}_\\text{Reconstruction error} - \\underbrace{D_{KL}(q(Z|X)||p(Z))}_\\text{Regularization}\\right] \\\\\n",
        "&amp;= \\int_{Z} \\left[\\log{p(X|Z)} - D_{KL}(q(Z|X)||p(Z))\\right] q(Z|X) dZ\n",
        "\\end{align*}$$\n",
        "The above integration problem can be solved via Monte Carlo integration as $D_{KL}(q(Z|X)||p(Z))$ is not intractable. Assuming that the probabilistic encoder $q(Z|X)$ is a multivariate Gaussian with a diagonal variance-covariance matrix we use the reparameterization trick to sample from this distribution say $M$ times in order to calculate the expectation term in the ELBO optimization problem. The reparameterization trick in this particular case amounts to sampling $M$ times from the standard Gaussian distribution, multiplying the samples by $\\sigma$ and adding $\\mu$ to the samples.\n",
        "\n",
        "$\\mu$ is our learnt representation used for the reconstruction of the raw data. If the learnt representation is useful it can then be used for other tasks as well.\n",
        "\n",
        "This is a powerful manner of combining Bayesian inference with deep learning. Variational inference used in this manner can be applied to various deep learning architectures and has further links with the Generative Adversarial Network (GAN). We explore the use of adversarial learning in representation learning in another repo/paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsjLpCTPacUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoding_dim = 500\n",
        "\n",
        "variational_autoencoder = VariationalAutoencoder(n_feat=X_train.shape[1],\n",
        "                                                 n_epoch=50,\n",
        "                                                 batch_size=100,\n",
        "                                                 encoder_layers=3,\n",
        "                                                 decoder_layers=3,\n",
        "                                                 n_hidden_units=1000,\n",
        "                                                 encoding_dim=encoding_dim,\n",
        "                                                 denoising=None)\n",
        "\n",
        "print(variational_autoencoder.autoencoder.summary())\n",
        "\n",
        "pipe_variational_autoencoder = Pipeline(steps=[(\"autoencoder\", variational_autoencoder),\n",
        "                                               (\"scaler_classifier\", scaler_classifier),\n",
        "                                               (\"classifier\", logistic)])\n",
        "\n",
        "pipe_variational_autoencoder = pipe_variational_autoencoder.fit(X_train, y_train)\n",
        "\n",
        "acc_variational_autoencoder = pipe_variational_autoencoder.score(X_test, y_test)\n",
        "\n",
        "print(\"The accuracy score for the MNIST classification task with a variational autoencoder: %.6f%%.\" % (acc_variational_autoencoder * 100))\n",
        "\n",
        "if encoding_dim == 2:\n",
        "    test_encoded_df = pd.DataFrame(pipe_variational_autoencoder.named_steps[\"autoencoder\"].encoder.predict(X_test))\n",
        "    test_encoded_df[\"Target\"] = y_test\n",
        "    test_encoded_df.columns.values[0:2] = [\"Encoding_1\", \"Encoding_2\"]\n",
        "\n",
        "    scaler_plot = MinMaxScaler(feature_range=(0.25, 0.75))\n",
        "    scaler_plot = scaler_plot.fit(test_encoded_df[[\"Encoding_1\", \"Encoding_2\"]])\n",
        "    test_encoded_df[[\"Encoding_1\", \"Encoding_2\"]] = scaler_plot.transform(test_encoded_df[[\"Encoding_1\", \"Encoding_2\"]])\n",
        "\n",
        "    cluster_plot = ggplot(test_encoded_df) + \\\n",
        "    geom_point(aes(x=\"Encoding_1\", \n",
        "                   y=\"Encoding_2\", \n",
        "                   fill=\"factor(Target)\"),\n",
        "               size=1,\n",
        "               color = \"black\") + \\\n",
        "    xlab(\"Encoding dimension 1\") + \\\n",
        "    ylab(\"Encoding dimension 2\") + \\\n",
        "    ggtitle(\"Variational autoencoder with 2-dimensional encoding\") + \\\n",
        "    theme_matplotlib()\n",
        "    print(cluster_plot)\n",
        "\n",
        "    n = 30\n",
        "    digit_size = 28\n",
        "    figure = np.zeros((digit_size * n, digit_size * n))\n",
        "    grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "    grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "\n",
        "    for i, xi in enumerate(grid_x):\n",
        "        for j, yi in enumerate(grid_y):\n",
        "            z_sample = np.array([[xi, yi]])\n",
        "            x_decoded = pipe_variational_autoencoder.named_steps[\"autoencoder\"].generator.predict(z_sample)\n",
        "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "            figure[i * digit_size: (i + 1) * digit_size, j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    plt.imshow(figure, cmap=\"Greys_r\")\n",
        "    plt.title(\"Variational Autoencoder (VAE) with 2-dimensional encoding\\nGenerating new images\")\n",
        "    plt.xlabel(\"Encoding dimension 1\")\n",
        "    plt.ylabel(\"Encoding dimension 2\")\n",
        "    plt.savefig(fname=\"VAE_Generated_Images.png\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5rJgmoga0Cn",
        "colab_type": "text"
      },
      "source": [
        "#MNIST: 2 Dimensional Convolutional Autoencoders\n",
        "For 2 dimensional convolution filters the idea is similar as for the 1 dimensional convolution filters. We will stick to our previously mentioned banking example to illustrate this point.\n",
        "\n",
        "$$\\begin{align*}\n",
        "x = \n",
        "\\begin{array}\n",
        "{l}\n",
        "\\text{Period 1} \\\\ \\text{Period 2} \\\\ \\text{Period 3} \\\\ \\text{Period 4} \\\\ \\text{Period 5}\n",
        "\\end{array}\n",
        "    \\left[\n",
        "    \\begin{array}\n",
        "    {ccc}\n",
        "    \\$0 &amp; \\$0 &amp; \\$0 \\\\\n",
        "    \\$0 &amp; \\$200 &amp; \\$0 \\\\\n",
        "    \\$100 &amp; \\$0 &amp; \\$0 \\\\\n",
        "    \\$0 &amp; \\$0 &amp; \\$300 \\\\\n",
        "    \\$0 &amp; \\$0 &amp; \\$0\n",
        "    \\end{array}\n",
        "    \\right]\n",
        "\\end{align*}$$\n",
        "In the 2 dimensional tensor of raw transactions data now we have 5 historical time periods, i.e., the rows, and 3 different transaction types, i.e., the columns. We will use a kernel, $\\alpha \\in \\mathbb{R}^{2\\times3}$, to extract useful features from the raw data. The choice of such a kernel means that we are interested in finding a feature map across all 3 transaction types and 2 historical time periods. We will use a stride length of 1 and a valid convolution to extract features over different patches of the raw data. The following will illustrate this point where $x_{\\text{patch}} \\subset x$:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\alpha &amp;=\n",
        "    \\left[\n",
        "    \\begin{array}\n",
        "    {ccc}\n",
        "    \\alpha_{1,1} &amp; \\alpha_{1,2} &amp; \\alpha_{1,3} \\\\\n",
        "    \\alpha_{2,1} &amp; \\alpha_{2,2} &amp; \\alpha_{2,3}\n",
        "    \\end{array}\n",
        "    \\right] \\\\\n",
        "x_{\\text{patch}} &amp;= \n",
        "    \\left[\n",
        "    \\begin{array}\n",
        "    {ccc}\n",
        "    \\$0 &amp; \\$0 &amp; \\$0 \\\\\n",
        "    \\$0 &amp; \\$200 &amp; \\$0\n",
        "    \\end{array}\n",
        "    \\right] \\\\\n",
        "\\mathbf{C}(x=x_{\\text{patch}}|\\alpha) &amp;= x * \\alpha \\\\\n",
        "&amp;= \\sum_{t=1}^{2} \\sum_{k=1}^{3} x_{t,k} \\alpha_{t,k}\n",
        "\\end{align*}$$\n",
        "The principles and ideas apply to 2 dimensional convolution filters as they do for their 1 dimensional counterparts there we will not repeat them here.\n",
        "\n",
        "$$\\begin{align*}\n",
        "&amp;X \\in \\mathbb{R}^{N \\times 28 \\times 28} \\\\\n",
        "&amp;E: \\mathbb{R}^{N \\times 28 \\times 28} \\rightarrow \\mathbb{R}^{N \\times K} \\\\\n",
        "&amp;D: \\mathbb{R}^{N \\times K} \\rightarrow \\mathbb{R}^{N \\times 28 \\times 28}\n",
        "\\end{align*}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQLGVd8gas9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "convolutional2D_autoencoder = Convolutional2DAutoencoder(input_shape=(int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5)), 1),\n",
        "                                                         n_epoch=5,\n",
        "                                                         batch_size=100,\n",
        "                                                         encoder_layers=3,\n",
        "                                                         decoder_layers=3,\n",
        "                                                         filters=100,\n",
        "                                                         kernel_size=(8, 8),\n",
        "                                                         strides=(1, 1),\n",
        "                                                         pool_size=(4, 4),\n",
        "                                                         denoising=None)\n",
        "\n",
        "print(convolutional2D_autoencoder.autoencoder.summary())\n",
        "\n",
        "pipe_convolutional2D_autoencoder = Pipeline(steps=[(\"autoencoder\", convolutional2D_autoencoder),\n",
        "                                                   (\"scaler_classifier\", scaler_classifier),\n",
        "                                                   (\"classifier\", logistic)])\n",
        "\n",
        "pipe_convolutional2D_autoencoder = pipe_convolutional2D_autoencoder.fit(np.reshape(X_train, [X_train.shape[0], int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5)), 1]),\n",
        "                                                                        y_train)\n",
        "\n",
        "acc_convolutional2D_autoencoder = pipe_convolutional2D_autoencoder.score(np.reshape(X_test, [X_test.shape[0], int(math.pow(X_test.shape[1], 0.5)), int(math.pow(X_test.shape[1], 0.5)), 1]), y_test)\n",
        "\n",
        "print(\"The accuracy score for the MNIST classification task with a 2 dimensional convolutional autoencoder: %.6f%%.\" % (acc_convolutional2D_autoencoder * 100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}